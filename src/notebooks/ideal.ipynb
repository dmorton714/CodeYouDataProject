{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d232fdb",
   "metadata": {},
   "source": [
    "### **Table of Contents**\n",
    "  * [read in data](#read-in-data)\n",
    "  * [Update cleaning code](#update-cleaning-code)\n",
    "  * [Generate report](#generate-report)\n",
    "  * [Plots](#plots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11a2343",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import dash\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0764cac1",
   "metadata": {},
   "source": [
    "## read in data\n",
    "Psudo code:\n",
    "- read in all the files in the data folder \n",
    "  - accounting for them being in xlsx or csv \n",
    "- dataframe variable name should end up being file name minus extension\n",
    "\n",
    "- This allows us to just drop in any export with any name and it should run. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd30f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for data in sys.path:\n",
    "#   if data.emndswith('.xlsx') or data.endswith('.csv'):\n",
    "#     df = pd.read_excel(data) if data.endswith('.xlsx') else pd.read_csv(data)\n",
    "#     print(f\"Data loaded from: {data}\")\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6f5506",
   "metadata": {},
   "source": [
    "## Update cleaning code \n",
    "Look at our cleaning code that we have. \n",
    "we should start to make changes to it to account for this. \n",
    "We need to make it so it so the program doesn't crash when something fails \n",
    "  - [Try Except logic updates](https://www.w3schools.com/python/python_try_except.asp)\n",
    "  - make the messages mean something meaningful\n",
    "Ideally we will not drop anything from our data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749ae60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DemographicsCleaning:\n",
    "    \"\"\"\n",
    "    A class for cleaning and preprocessing demographic data.\n",
    "\n",
    "    Provides methods to:\n",
    "    - Remove unused or mostly null columns\n",
    "    - Normalize gender values\n",
    "    - Split the 'Race' column into multiple race columns\n",
    "    - Drop duplicate rows\n",
    "    \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def remove_unused_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Remove columns with mostly null values or unnecessary information.\n",
    "\n",
    "        Args:\n",
    "            df (pd.DataFrame): Input dataframe containing demographic data.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: Dataframe with specified columns removed.\n",
    "        \"\"\"\n",
    "        columns_to_drop = [\n",
    "            'First Name', 'Last Name', 'Ethnicity Hispanic/Latino',\n",
    "            'Single Parent', 'Ex-Offender', 'Program: Program Name', 'Outcome'\n",
    "        ]\n",
    "        return df.drop(columns=columns_to_drop, errors='ignore')\n",
    "\n",
    "    @staticmethod\n",
    "    def normalize_gender(df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Normalize gender values by combining 'Transgender male to female'\n",
    "        and 'Transgender female to male' into a single 'Transgender' category.\n",
    "\n",
    "        Args:\n",
    "            df (pd.DataFrame): Input dataframe containing a 'Gender' column.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: Dataframe with normalized gender values.\n",
    "        \"\"\"\n",
    "        df['Gender'] = df['Gender'].replace({\n",
    "            'Transgender male to female': 'Transgender',\n",
    "            'Transgender female to male': 'Transgender'\n",
    "        })\n",
    "        return df\n",
    "\n",
    "    @staticmethod\n",
    "    def split_race_column(df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Split the 'Race' column into multiple columns\n",
    "        if multiple races are selected.\n",
    "\n",
    "        Args:\n",
    "            df (pd.DataFrame): Input dataframe containing a 'Race' column.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: Dataframe with new columns Race_1, Race_2, etc.\n",
    "        \"\"\"\n",
    "        splitting = df['Race'].str.split(';', expand=True)\n",
    "        splitting.columns = [f'Race_{i+1}' for i in range(splitting.shape[1])]\n",
    "        df = pd.concat([df.drop(columns=['Race']), splitting], axis=1)\n",
    "        return df\n",
    "\n",
    "    @staticmethod\n",
    "    def drop_duplicates(df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Remove duplicate rows from the dataframe.\n",
    "\n",
    "        Args:\n",
    "            df (pd.DataFrame): Input dataframe.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: Dataframe without duplicate rows.\n",
    "        \"\"\"\n",
    "        return df.drop_duplicates()\n",
    "\n",
    "    @classmethod\n",
    "    def clean(cls, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Perform the full data cleaning process on demographics data.\n",
    "\n",
    "        Steps include:\n",
    "        - Removing unused or mostly null columns\n",
    "        - Normalizing gender values\n",
    "        - Splitting the 'Race' column into multiple race columns\n",
    "        - Dropping duplicate rows\n",
    "\n",
    "        Args:\n",
    "            df (pd.DataFrame): Raw demographics dataframe.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: Cleaned dataframe ready for analysis.\n",
    "        \"\"\"\n",
    "        df = cls.remove_unused_columns(df)\n",
    "        df = cls.normalize_gender(df)\n",
    "        df = cls.split_race_column(df)\n",
    "        df = cls.drop_duplicates(df)\n",
    "        return df\n",
    "\n",
    "\n",
    "class WorceCleaning:\n",
    "    \"\"\"\n",
    "    A placeholder for a class that can be used to clean Worce data.\n",
    "    This class can be extended in the future to include specific cleaning methods.\n",
    "    \"\"\"\n",
    "    @staticmethod\n",
    "    def clean(df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Placeholder method for cleaning Worce data.\n",
    "        Currently does nothing but can be extended in the future.\n",
    "\n",
    "        Args:\n",
    "            df (pd.DataFrame): Input dataframe containing Worce data.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: Unchanged dataframe.\n",
    "        \"\"\"\n",
    "    pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ddbb4c0",
   "metadata": {},
   "source": [
    "## Generate report \n",
    "\n",
    "- Overall completion of program only accounting for the new style of classes m1-m4\n",
    "- completion by year \n",
    "- completion over all by pathway \n",
    "- completion by year by pathway \n",
    "- Feel free to get creative here adding gender etc to get us a better understanding \n",
    "- education level and the above... \n",
    "- export this as a txt file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6485e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "859cf674",
   "metadata": {},
   "source": [
    "## Plots \n",
    "- Look at the various plots \n",
    "- make a consistent color scheme\n",
    "- pick the plots that go with the report above \n",
    "- make missing plots \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81009a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_salary_by_gender(data):\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    sns.boxplot(data=data, x='Gender', y='Salary')\n",
    "    plt.title(\"Salary Distribution by Gender\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_avg_salary_by_city(data):\n",
    "    region_salary = data.groupby('Mailing City')['Salary'].mean().sort_values()\n",
    "    region_salary.plot(kind='barh', figsize=(8, 5), title=\"Average Salary by KY Region\")\n",
    "    plt.xlabel(\"Average Salary\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_placements_over_time(data):\n",
    "    data.set_index('Start Date').resample('M').size().plot(kind='line', marker='o', figsize=(10, 4))\n",
    "    plt.title(\"Number of Placements Over Time\")\n",
    "    plt.ylabel(\"Placements\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_placement_type_by_program(data):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.countplot(data=data, x='ATP Placement Type', hue='Program: Program Name')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.title(\"Placement Type by Program\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_top_cities(data):\n",
    "    city_counts = data['Mailing City'].value_counts().head(10)\n",
    "    city_counts.plot(kind='bar', title='Top Cities by Participant Count', figsize=(8, 4))\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f471c68",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'most_common_pathways_taken_data'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     15\u001b[39m sys.path.append(parent_dir)\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdash\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dash, dcc, html, Input, Output\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmost_common_pathways_taken_data\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Most_common_pathways_taken_data\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcompletion_rate_data\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Completion_rate_data\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcleaning_enrollments_data\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m EnrollmentsCleaning\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'most_common_pathways_taken_data'"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# # Visualization examples\n",
    "# \n",
    "# Visualizion was not turn into a class because the project will use Google Locker for dashboard creation, this notebook only works to showcase how to use the Data Manipulation classes.\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Imports\n",
    "\n",
    "# %%\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import os\n",
    "import sys\n",
    "parent_dir = os.path.abspath(\"..\")\n",
    "sys.path.append(parent_dir)\n",
    "from dash import Dash, dcc, html, Input, Output\n",
    "from most_common_pathways_taken_data import Most_common_pathways_taken_data\n",
    "from completion_rate_data import Completion_rate_data\n",
    "from cleaning_enrollments_data import EnrollmentsCleaning\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Cleaning data\n",
    "# \n",
    "# This step should be done before the use of any of the Data classes\n",
    "\n",
    "# %%\n",
    "cleaner = EnrollmentsCleaning(pd.read_excel('../../data/ARC_Enrollments.xlsx'))\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Most common pathway taken:\n",
    "\n",
    "# %%\n",
    "def Dash_most_selected_path_by_cohort() -> Dash: # Need to pass the dataframe argument because of how the Data is structure\n",
    "    app = Dash(__name__)\n",
    "    # Const\n",
    "    data_class = Most_common_pathways_taken_data(cleaner.Get_clean_data())\n",
    "\n",
    "    dropdown_options = data_class.Get_cohorts_list()\n",
    "    pathway_color = {\n",
    "        'Web Development M1': 'blue',\n",
    "        'Data Analysis M1': 'red', \n",
    "        'Software Development M1': 'green',\n",
    "        'Quality Assurance M1': 'yellow', \n",
    "        'User Experience M1': 'purple'\n",
    "    }\n",
    "\n",
    "    # Display\n",
    "    app.layout = html.Div([\n",
    "        html.H2('Cohorts', style={'text-align': \"center\"}),\n",
    "        html.P('Select Cohort:'),\n",
    "        dcc.Dropdown(\n",
    "            id=\"dropdown\",\n",
    "            options=dropdown_options,\n",
    "            value=dropdown_options[0],\n",
    "            clearable=False,\n",
    "        ),\n",
    "        dcc.Graph(id=\"graph\")\n",
    "        \n",
    "    ], style={'backgroundColor':'white'})\n",
    "\n",
    "    @app.callback(\n",
    "        Output(\"graph\", \"figure\"),\n",
    "        Input(\"dropdown\", \"value\"))\n",
    "\n",
    "    # Graph\n",
    "    def tt(time):\n",
    "        df = data_class.Get_data_by_cohort(time)\n",
    "        fig = px.pie(df, names='Service', values='count', color='Service', color_discrete_map=pathway_color)\n",
    "        return fig\n",
    "\n",
    "    return app\n",
    "\n",
    "    # TODO: Add number of students per each cohort \n",
    "    # TODO: Fix the options on the selection \n",
    "    # TODO: make colors better\n",
    "\n",
    "Dash_most_selected_path_by_cohort().run(debug=True, port=8052)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Compleation rates:\n",
    "\n",
    "# %%\n",
    "def Dash_completion_rates_by_path() -> Dash: # TODO: fix data structure so visualization doesn't use df\n",
    "    app2 = Dash(__name__)\n",
    "    # Const\n",
    "    data_class = Completion_rate_data(cleaner.Get_clean_data())\n",
    "    completion_df = data_class.Get_completion_percentages().round(2)\n",
    "    options = data_class.Get_pathways_name(completion_df)\n",
    "\n",
    "    # Display\n",
    "    app2.layout = html.Div([\n",
    "        html.H2('Pathways Completion', style={'text-align': \"center\"}),\n",
    "        html.P('Select pathway:'),\n",
    "        dcc.Dropdown(\n",
    "            id=\"dropdown\",\n",
    "            options=options,\n",
    "            value=options[0],\n",
    "            clearable=False,\n",
    "        ),\n",
    "        dcc.Graph(id=\"graph\")\n",
    "        \n",
    "    ], style={'backgroundColor':'white'})\n",
    "\n",
    "    @app2.callback(\n",
    "        Output(\"graph\", \"figure\"),\n",
    "        Input(\"dropdown\", \"value\"))\n",
    "\n",
    "    # Graph\n",
    "    # TODO: Need to add an extra selection box with the cohorts\n",
    "    def Display_pathway_completion(p):\n",
    "        df = completion_df[completion_df['Pathway'] == p]\n",
    "        fig = px.bar(df, x='Module', y='Successfully Completed')\n",
    "        return fig\n",
    "\n",
    "    return app2\n",
    "\n",
    "Dash_completion_rates_by_path().run(debug=True, port=8053)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f905708f",
   "metadata": {},
   "source": [
    "TOC generator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4fc7116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- ✅ Copy the Markdown below and paste it into a new markdown cell ---\n",
      "\n",
      "### **Table of Contents**\n",
      "  * [read in data](#read-in-data)\n",
      "  * [Update cleaning code](#update-cleaning-code)\n",
      "  * [Generate report](#generate-report)\n",
      "  * [Plots](#plots)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "\n",
    "def generate_toc_from_notebook(notebook_path):\n",
    "    \"\"\"\n",
    "    Parses a local .ipynb file and generates Markdown for a Table of Contents.\n",
    "    \"\"\"\n",
    "    if not os.path.isfile(notebook_path):\n",
    "        print(f\"❌ Error: File not found at '{notebook_path}'\")\n",
    "        return\n",
    "\n",
    "    with open(notebook_path, 'r', encoding='utf-8') as f:\n",
    "        notebook = json.load(f)\n",
    "\n",
    "    toc_markdown = \"### **Table of Contents**\\n\"\n",
    "    for cell in notebook.get('cells', []):\n",
    "        if cell.get('cell_type') == 'markdown':\n",
    "            for line in cell.get('source', []):\n",
    "                if line.strip().startswith('#'):\n",
    "                    level = line.count('#')\n",
    "                    title = line.strip('#').strip()\n",
    "                    link = title.lower().replace(' ', '-').strip('-.()')\n",
    "                    indent = '  ' * (level - 1)\n",
    "                    toc_markdown += f\"{indent}* [{title}](#{link})\\n\"\n",
    "\n",
    "    print(\"\\n--- ✅ Copy the Markdown below and paste it \"\n",
    "          \"into a new markdown cell ---\\n\")\n",
    "    print(toc_markdown)\n",
    "\n",
    "\n",
    "notebook_path = 'ideal.ipynb'\n",
    "generate_toc_from_notebook(notebook_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
