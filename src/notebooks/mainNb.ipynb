{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d232fdb",
   "metadata": {},
   "source": [
    "## **Table of Contents**\n",
    "\n",
    "  * [Function To Read in the Data!](#function-to-read-in-the-data!)\n",
    "  * [Example usage](#example-usage)\n",
    "      * [To Access a DataFrame in the list](#to-access-a-dataframe-in-the-list)\n",
    "      * [To Remove Spaces in DataFrame name](#to-remove-spaces-in-dataframe-name)\n",
    "  * [Update cleaning code](#update-cleaning-code)\n",
    "* [example usage of each method](#example-usage-of-each-method)\n",
    "    * [Sample use of the clean_salary function.](#sample-use-of-the-clean_salary-function)\n",
    "* [Example of making a test](#example-of-making-a-test)\n",
    "  * [Generate report](#generate-report)\n",
    "* [pathway information](#pathway-information)\n",
    "  * [Plots](#plots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d11a2343",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from typing import Dict, Union\n",
    "from pathlib import Path\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import pandas.testing as pdt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0764cac1",
   "metadata": {},
   "source": [
    "## Function To Read in the Data!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7cd30f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_folder(\n",
    "    folder_path: Union[str, os.PathLike] = \"../../data\"\n",
    ") -> Dict[str, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Load all CSV/XLS/XLSX files in a folder into pandas DataFrames.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    folder_path : str | os.PathLike, optional\n",
    "        Path to the folder containing the files. Defaults to \"../../data\".\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Dict[str, pandas.DataFrame]\n",
    "        A mapping from the file's stem (filename without extension) to its\n",
    "        loaded DataFrame. For example, \"employees.csv\" -> key \"employees\".\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    FileNotFoundError\n",
    "        If `folder_path` does not exist.\n",
    "    PermissionError\n",
    "        If the folder or files cannot be accessed due to permissions.\n",
    "    pd.errors.EmptyDataError\n",
    "        If a CSV file is empty and cannot be parsed.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    - Supported extensions: .csv, .xls, .xlsx (case-insensitive).\n",
    "    - If both `name.csv` and `name.xlsx` exist, the later one encountered will\n",
    "      overwrite the earlier entry for key `name`.\n",
    "    \"\"\"\n",
    "    path = Path(folder_path)\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(f\"Folder not found: {path.resolve()}\")\n",
    "\n",
    "    dataframes: Dict[str, pd.DataFrame] = {}\n",
    "    for p in path.iterdir():\n",
    "        if not p.is_file():\n",
    "            continue\n",
    "\n",
    "        ext = p.suffix.lower()\n",
    "        if ext == \".csv\":\n",
    "            df = pd.read_csv(p)\n",
    "        elif ext in {\".xlsx\", \".xls\"}:\n",
    "            df = pd.read_excel(p)\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        dataframes[p.stem] = df\n",
    "\n",
    "    return dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714769cf",
   "metadata": {},
   "source": [
    "## Example usage\n",
    "\n",
    "```python\n",
    "dfs = load_data_folder()\n",
    "dfs.keys()\n",
    "```\n",
    "\n",
    "output:\n",
    "\n",
    "```bash\n",
    "dict_keys(['ARC_Enrollments', 'ARC_Application', 'All_demographics_and_programs'])\n",
    "```\n",
    "\n",
    "#### To Access a DataFrame in the list\n",
    "\n",
    "```python\n",
    "all_demo = dfs['All_demographics_and_programs']\n",
    "all_demo.head(1)\n",
    "```\n",
    "\n",
    "output:\n",
    "|col 1|col 2|col 3|\n",
    "|:--:|:--:|:--:|\n",
    "|3.14|name|apple|\n",
    "\n",
    "#### To Remove Spaces in DataFrame name\n",
    "\n",
    "```python\n",
    "for name, df in dfs.items():\n",
    "    safe_name = name.replace(\" \", \"_\")\n",
    "    globals()[safe_name] = df\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "15c0e5af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['ARC_Enrollments', 'ARC_Application', 'All_demographics_and_programs'])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs = load_data_folder()\n",
    "dfs.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f643e1d8",
   "metadata": {},
   "source": [
    "How to call the dataframe from the list above\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5875ef3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Auto Id</th>\n",
       "      <th>First Name</th>\n",
       "      <th>Last Name</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Race</th>\n",
       "      <th>Ethnicity Hispanic/Latino</th>\n",
       "      <th>Outcome</th>\n",
       "      <th>Veteran</th>\n",
       "      <th>Ex-Offender</th>\n",
       "      <th>Justice Involved</th>\n",
       "      <th>Single Parent</th>\n",
       "      <th>Program: Program Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>202107-1206</td>\n",
       "      <td>name</td>\n",
       "      <td>name</td>\n",
       "      <td>Male</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reimage 21-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>202107-1206</td>\n",
       "      <td>name</td>\n",
       "      <td>name</td>\n",
       "      <td>Male</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reimage 21-22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Auto Id First Name Last Name Gender                       Race  \\\n",
       "0  202107-1206       name      name   Male  Black or African American   \n",
       "1  202107-1206       name      name   Male  Black or African American   \n",
       "\n",
       "   Ethnicity Hispanic/Latino Outcome Veteran Ex-Offender Justice Involved  \\\n",
       "0                        NaN     NaN      No         NaN              NaN   \n",
       "1                        NaN     NaN      No         NaN              NaN   \n",
       "\n",
       "  Single Parent Program: Program Name  \n",
       "0           NaN         Reimage 21-22  \n",
       "1           NaN         Reimage 21-22  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_demo = dfs['All_demographics_and_programs']\n",
    "all_demo.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e00a727",
   "metadata": {},
   "source": [
    "Little for loop at access the dataframes individually\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c3c755a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, df in dfs.items():\n",
    "    safe_name = name.replace(\" \", \"_\")\n",
    "    globals()[safe_name] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fa63b693",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Auto Id</th>\n",
       "      <th>First Name</th>\n",
       "      <th>Last Name</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Race</th>\n",
       "      <th>Ethnicity Hispanic/Latino</th>\n",
       "      <th>Outcome</th>\n",
       "      <th>Veteran</th>\n",
       "      <th>Ex-Offender</th>\n",
       "      <th>Justice Involved</th>\n",
       "      <th>Single Parent</th>\n",
       "      <th>Program: Program Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>202107-1206</td>\n",
       "      <td>name</td>\n",
       "      <td>name</td>\n",
       "      <td>Male</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reimage 21-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>202107-1206</td>\n",
       "      <td>name</td>\n",
       "      <td>name</td>\n",
       "      <td>Male</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reimage 21-22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Auto Id First Name Last Name Gender                       Race  \\\n",
       "0  202107-1206       name      name   Male  Black or African American   \n",
       "1  202107-1206       name      name   Male  Black or African American   \n",
       "\n",
       "   Ethnicity Hispanic/Latino Outcome Veteran Ex-Offender Justice Involved  \\\n",
       "0                        NaN     NaN      No         NaN              NaN   \n",
       "1                        NaN     NaN      No         NaN              NaN   \n",
       "\n",
       "  Single Parent Program: Program Name  \n",
       "0           NaN         Reimage 21-22  \n",
       "1           NaN         Reimage 21-22  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "All_demographics_and_programs.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83d9a39",
   "metadata": {},
   "source": [
    "Should we switch to this rather than the 2 step process above?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3a009686",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_folder(\n",
    "    folder_path: Union[str, os.PathLike] = \"../../data\",\n",
    "    safe_names: bool = False\n",
    ") -> Dict[str, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Load all CSV/XLS/XLSX files in a folder into pandas DataFrames.\n",
    "    ...\n",
    "    safe_names : bool, optional\n",
    "        If True, replace spaces in filenames with underscores for dict keys.\n",
    "    \"\"\"\n",
    "    path = Path(folder_path)\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(f\"Folder not found: {path.resolve()}\")\n",
    "\n",
    "    dataframes: Dict[str, pd.DataFrame] = {}\n",
    "    for p in path.iterdir():\n",
    "        if not p.is_file():\n",
    "            continue\n",
    "\n",
    "        ext = p.suffix.lower()\n",
    "        if ext == \".csv\":\n",
    "            df = pd.read_csv(p)\n",
    "        elif ext in {\".xlsx\", \".xls\"}:\n",
    "            df = pd.read_excel(p)\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        key = p.stem.replace(\" \", \"_\") if safe_names else p.stem\n",
    "        dataframes[key] = df\n",
    "\n",
    "    return dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ce7ffc41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['ARC_Enrollments', 'ARC_Application', 'All_demographics_and_programs'])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs = load_data_folder(safe_names=True)\n",
    "dfs.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6f5506",
   "metadata": {},
   "source": [
    "## Update cleaning code\n",
    "\n",
    "- Look at our cleaning code that we have.\n",
    "- we should start to make changes to it to account for this.\n",
    "- We need to make it so it so the program doesn't crash when something fails\n",
    "  - [Try Except logic updates](https://www.w3schools.com/python/python_try_except.asp)\n",
    "  - make the messages mean something meaningful\n",
    "- Ideally we will not drop anything from our data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29302c63",
   "metadata": {},
   "source": [
    "Will update this a bit with usage etc...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "749ae60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataCleaner:\n",
    "    \"\"\"\n",
    "    A utility class for cleaning and standardizing tabular datasets.\n",
    "\n",
    "    This class wraps a pandas DataFrame and provides a set of \n",
    "    convenience methods for common data cleaning tasks such as:\n",
    "\n",
    "    - Dropping unnecessary columns.\n",
    "    - Filling missing values with specified defaults.\n",
    "    - Replacing or normalizing categorical values.\n",
    "    - Converting data types safely (including datetime).\n",
    "    - Standardizing demographic fields (e.g., gender, race).\n",
    "    - Parsing and normalizing salary values.\n",
    "\n",
    "    All methods are designed to fail gracefully:\n",
    "    - If a target column does not exist, it is skipped.\n",
    "    - If an operation fails due to incompatible data, a warning \n",
    "      is printed and the DataFrame remains unchanged.\n",
    "\n",
    "    Most methods return `self`, enabling method chaining:\n",
    "\n",
    "    Example\n",
    "    -------\n",
    "    >>> cleaner = DataCleaner(df)\n",
    "    >>> clean_df = (\n",
    "    ...     cleaner\n",
    "    ...     .drop_columns([\"UnusedCol\"])\n",
    "    ...     .fillna({\"Age\": 0, \"City\": \"Unknown\"})\n",
    "    ...     .normalize_gender()\n",
    "    ...     .normalize_race()\n",
    "    ...     .clean_salary()\n",
    "    ...     .finalize()\n",
    "    ...     )\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, df: pd.DataFrame):\n",
    "        self.df = df.copy()\n",
    "\n",
    "    def drop_columns(self, cols_to_drop) -> \"Self\":\n",
    "        \"\"\"\n",
    "        Drop one or more columns from the DataFrame safely.\n",
    "\n",
    "        This method attempts to drop the specified columns. If a column \n",
    "        does not exist, it is ignored (no error is raised). If dropping \n",
    "        fails due to another issue (e.g., invalid argument type), a \n",
    "        warning is printed and the DataFrame is left unchanged.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        cols_to_drop : str or list of str\n",
    "            Column name or list of column names to drop.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Self\n",
    "            The current instance, allowing method chaining.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.df = self.df.drop(columns=cols_to_drop, errors='ignore')\n",
    "        except Exception as e:\n",
    "            print(f\"[Warning] Failed dropping columns: {e}\")\n",
    "        return self\n",
    "\n",
    "    def fillna(self, fill_map: dict) -> \"Self\":\n",
    "        \"\"\"\n",
    "        Fill missing (NaN) values in specified columns safely.\n",
    "\n",
    "        For each column provided in the mapping, this method replaces \n",
    "        NaN values with the specified fill value. Columns not present \n",
    "        in the DataFrame are skipped. If filling fails for a column \n",
    "        (e.g., due to incompatible data types), a warning is printed \n",
    "        and that column is left unchanged.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        fill_map : dict\n",
    "            A dictionary mapping {column_name: fill_value} pairs.\n",
    "            Example: {\"age\": 0, \"city\": \"Unknown\"}\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Self\n",
    "            The current instance, allowing method chaining.\n",
    "        \"\"\"\n",
    "        for col, val in fill_map.items():\n",
    "            try:\n",
    "                if col in self.df.columns:\n",
    "                    self.df[col] = self.df[col].fillna(val)\n",
    "            except Exception as e:\n",
    "                print(f\"[Warning] Failed filling NaN for {col}: {e}\")\n",
    "        return self\n",
    "\n",
    "    def replace_column_values(self, col: str, replacements: dict) -> \"Self\":\n",
    "        \"\"\"\n",
    "        Replace values in a specified DataFrame column using a mapping dictionary.\n",
    "\n",
    "        This method attempts to apply the given replacements safely. \n",
    "        If the column exists, it replaces matching values based on the \n",
    "        provided mapping. If an error occurs during replacement \n",
    "        (e.g., invalid mapping or data type mismatch), a warning \n",
    "        is printed and the DataFrame is left unchanged.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        col : str\n",
    "            The name of the column in the DataFrame to modify.\n",
    "        replacements : dict\n",
    "            A mapping of {old_value: new_value} pairs to replace.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Self\n",
    "            The current instance, allowing method chaining.\n",
    "        Sample usage:\n",
    "        >>> cleaner = DataCleaner(df)\n",
    "        >>> cleaner.replace_column_values(\"status\", {\"yes\": 1, \"no\": 0})\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if col in self.df.columns:\n",
    "                self.df[col] = self.df[col].replace(replacements)\n",
    "        except Exception as e:\n",
    "            print(f\"[Warning] Failed replacing values in {col}: {e}\")\n",
    "        return self\n",
    "\n",
    "    def convert_datetime(self, col, dtype, errors=\"ignore\"):\n",
    "        \"\"\"\n",
    "        Convert a column to a specified dtype, with special handling for datetimes.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        col : str\n",
    "            Name of the column to convert.\n",
    "        dtype : str or type\n",
    "            Target dtype. If the string contains \"datetime\", the method will use\n",
    "            `pandas.to_datetime` for conversion. Otherwise, it uses `.astype()`.\n",
    "        errors : {\"ignore\", \"raise\", \"coerce\"}, default \"ignore\"\n",
    "            Error handling behavior:\n",
    "            - \"ignore\": invalid parsing will return the original input.\n",
    "            - \"raise\": raises an exception on invalid parsing.\n",
    "            - \"coerce\": invalid parsing will be set as NaT (for datetime) or NaN.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self : DataFrameCleaner\n",
    "            The instance with the modified DataFrame, allowing for method chaining.\n",
    "\n",
    "        Notes\n",
    "        -----\n",
    "        - For datetime conversion, the method forces `errors=\"coerce\"` to ensure\n",
    "        invalid values are converted to NaT instead of raising.\n",
    "        - For non-datetime conversions, the provided `errors` argument is passed\n",
    "        directly to `.astype()`.\n",
    "        - If the column does not exist, no action is taken.\n",
    "\n",
    "        Examples\n",
    "        --------\n",
    "        >>> cleaner.convert_datetime(\"StartDate\", \"datetime64[ns]\")\n",
    "        >>> cleaner.convert_datetime(\"Age\", \"int\", errors=\"coerce\")\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if col in self.df.columns:\n",
    "                if \"datetime\" in str(dtype):\n",
    "                    self.df[col] = pd.to_datetime(\n",
    "                        self.df[col], errors=\"coerce\")\n",
    "                else:\n",
    "                    self.df[col] = self.df[col].astype(dtype, errors=errors)\n",
    "        except Exception as e:\n",
    "            print(f\"[Warning] Failed dtype conversion on {col}: {e}\")\n",
    "        return self\n",
    "\n",
    "    def normalize_gender(self) -> \"Self\":\n",
    "        \"\"\"\n",
    "        Standardize gender labels in the DataFrame.\n",
    "\n",
    "        This method looks for a column named \"Gender\" and replaces \n",
    "        specific transgender categories with the unified label \n",
    "        \"Transgender\". If the column does not exist or the replacement \n",
    "        fails (e.g., due to unexpected data types), the method prints a \n",
    "        warning and leaves the DataFrame unchanged.\n",
    "\n",
    "        Replacements performed:\n",
    "            - \"Transgender male to female\" → \"Transgender\"\n",
    "            - \"Transgender female to male\" → \"Transgender\"\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Self\n",
    "            The current instance, allowing method chaining.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if \"Gender\" in self.df.columns:\n",
    "                self.df[\"Gender\"] = self.df[\"Gender\"].replace({\n",
    "                    \"Transgender male to female\": \"Transgender\",\n",
    "                    \"Transgender female to male\": \"Transgender\"\n",
    "                })\n",
    "        except Exception as e:\n",
    "            print(f\"[Warning] Failed gender normalization: {e}\")\n",
    "        return self\n",
    "\n",
    "    def normalize_race(self) -> \"Self\":\n",
    "        \"\"\"\n",
    "        Normalize the 'Race' column so that multi-value entries are \n",
    "        collapsed into a single category \"Two or More Races\".\n",
    "\n",
    "        Behavior\n",
    "        --------\n",
    "        - Single race values are kept as-is.\n",
    "        - Multi-value entries separated by \";\" or \",\" are replaced with\n",
    "        \"Two or More Races\".\n",
    "\n",
    "        Example\n",
    "        -------\n",
    "        Original: \"White;Asian\" → \"Two or More Races\"\n",
    "        Original: \"White,Asian\" → \"Two or More Races\"\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Self\n",
    "            The current instance, allowing method chaining.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if \"Race\" in self.df.columns:\n",
    "                self.df[\"Race\"] = self.df[\"Race\"].astype(str).apply(\n",
    "                    lambda x: \"Two or More Races\" if (\n",
    "                        \";\" in x or \",\" in x) else x\n",
    "                )\n",
    "        except Exception as e:\n",
    "            print(f\"[Warning] Failed race normalization: {e}\")\n",
    "        return self\n",
    "\n",
    "    def clean_salary(self, hours_per_year: int = 2080):\n",
    "        \"\"\"\n",
    "        Clean and standardize salary values in the DataFrame.\n",
    "\n",
    "        Steps performed:\n",
    "        1. Remove currency symbols, commas, and shorthand (e.g., \"$50k\" → 50000).\n",
    "        2. Handle ranges by converting them to the average value \n",
    "            (e.g., \"50,000–70,000\" → 60000).\n",
    "        3. Handle shorthand \"M\" (e.g., \"$1.5M\" → 1,500,000).\n",
    "        4. Convert values to numeric, coercing invalid entries to NaN.\n",
    "        5. Treat values <= 200 as hourly wages and convert to annual salaries \n",
    "            (multiplied by `hours_per_year`).\n",
    "        6. Drop unrealistic values greater than 1,000,000 (set to NaN).\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        hours_per_year : int, optional (default=2080)\n",
    "            Number of work hours in a year for converting hourly to annual salary.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "            The current instance with the cleaned Salary column.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if \"Salary\" in self.df.columns:\n",
    "                self.df[\"Salary\"] = self.df[\"Salary\"].astype(str)\n",
    "\n",
    "                def parse_salary(val: str):\n",
    "                    val = val.strip()\n",
    "                    if not val or val.lower() in {\"nan\", \"none\"}:\n",
    "                        return None\n",
    "\n",
    "                    # Normalize dash types (hyphen, en dash, em dash \"-\")\n",
    "                    val = re.sub(r\"[–—]\", \"-\", val)\n",
    "\n",
    "                    # Handle range like \"50k-70k\" or \"50,000-70,000\"\n",
    "                    if \"-\" in val:\n",
    "                        parts = val.split(\"-\")\n",
    "                        nums = [parse_salary(p) for p in parts if p.strip()]\n",
    "                        nums = [n for n in nums if n is not None]\n",
    "                        return sum(nums) / len(nums) if nums else None\n",
    "\n",
    "                    # Remove $, commas, spaces\n",
    "                    val = re.sub(r\"[\\$,]\", \"\", val)\n",
    "\n",
    "                    # Handle shorthand k/K (e.g., \"50k\" → 50000)\n",
    "                    match_k = re.match(r\"^(\\d+(\\.\\d+)?)[kK]$\", val)\n",
    "                    if match_k:\n",
    "                        return float(match_k.group(1)) * 1000\n",
    "\n",
    "                    # Handle shorthand M (e.g., \"1.5M\" → 1500000)\n",
    "                    match_m = re.match(r\"^(\\d+(\\.\\d+)?)[mM]$\", val)\n",
    "                    if match_m:\n",
    "                        return float(match_m.group(1)) * 1_000_000\n",
    "\n",
    "                    # Plain number (integer or float)\n",
    "                    try:\n",
    "                        return float(val)\n",
    "                    except ValueError:\n",
    "                        return None\n",
    "\n",
    "                # Apply parsing\n",
    "                self.df[\"Salary\"] = self.df[\"Salary\"].apply(parse_salary)\n",
    "\n",
    "                # Convert small numbers (hourly) to annual\n",
    "                self.df.loc[self.df[\"Salary\"] <=\n",
    "                            200, \"Salary\"] *= hours_per_year\n",
    "\n",
    "                # Drop unrealistic salaries\n",
    "                self.df.loc[self.df[\"Salary\"] > 1_000_000, \"Salary\"] = None\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[Warning] Failed salary cleaning: {e}\")\n",
    "\n",
    "        return self\n",
    "\n",
    "    def finalize(self) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Finalize and return the cleaned DataFrame.\n",
    "\n",
    "        This method should be called at the end of a cleaning pipeline \n",
    "        to retrieve the fully processed DataFrame after all applied \n",
    "        transformations.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        pd.DataFrame\n",
    "            The cleaned and transformed DataFrame.\n",
    "        \"\"\"\n",
    "        return self.df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84a5b95",
   "metadata": {},
   "source": [
    "# example usage of each method\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "329da719",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2d/yt4_w6zn5pbfjg_jx5sdmm180000gn/T/ipykernel_42885/3987826742.py:163: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  self.df[col] = pd.to_datetime(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Auto Id</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Race</th>\n",
       "      <th>Ethnicity Hispanic/Latino</th>\n",
       "      <th>Outcome</th>\n",
       "      <th>Veteran</th>\n",
       "      <th>Ex-Offender</th>\n",
       "      <th>Justice Involved</th>\n",
       "      <th>Single Parent</th>\n",
       "      <th>Program: Program Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaT</td>\n",
       "      <td>Male</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>0</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Reimage 21-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaT</td>\n",
       "      <td>Male</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>0</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Reimage 21-22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Auto Id Gender                       Race Ethnicity Hispanic/Latino  \\\n",
       "0     NaT   Male  Black or African American                   Unknown   \n",
       "1     NaT   Male  Black or African American                   Unknown   \n",
       "\n",
       "   Outcome Veteran Ex-Offender Justice Involved Single Parent  \\\n",
       "0  Unknown       0     Unknown          Unknown       Unknown   \n",
       "1  Unknown       0     Unknown          Unknown       Unknown   \n",
       "\n",
       "  Program: Program Name  \n",
       "0         Reimage 21-22  \n",
       "1         Reimage 21-22  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaner = DataCleaner(all_demo)\n",
    "\n",
    "clean_df = (\n",
    "    cleaner\n",
    "    # 1. Drop unneeded columns\n",
    "    .drop_columns([\"First Name\", \"Last Name\"])\n",
    "\n",
    "    # 2. Fill missing values\n",
    "    .fillna({\n",
    "        \"Outcome\": \"Unknown\",\n",
    "        \"Veteran\": \"Unknown\",\n",
    "        \"Ex-Offender\": \"Unknown\",\n",
    "        \"Justice Involved\": \"Unknown\",\n",
    "        \"Single Parent\": \"Unknown\",\n",
    "        \"Ethnicity Hispanic/Latino\": \"Unknown\"\n",
    "    })\n",
    "\n",
    "    # 3. Replace specific column values\n",
    "    .replace_column_values(\"Veteran\", {\"No\": 0, \"Yes\": 1, \"Unknown\": -1})\n",
    "\n",
    "    # 4. Convert a column to datetime (pretend Auto Id is a date code)\n",
    "    .convert_datetime(\"Auto Id\", \"datetime64[ns]\")  # will fail gracefully\n",
    "\n",
    "    # 5. Normalize gender labels\n",
    "    .normalize_gender()\n",
    "\n",
    "    # 6. Normalize race column (collapse multi-value)\n",
    "    .normalize_race()\n",
    "\n",
    "    # 7. Clean salary column\n",
    "    .clean_salary()\n",
    "\n",
    "    # 8. Finalize and return cleaned DataFrame\n",
    "    .finalize()\n",
    ")\n",
    "\n",
    "clean_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb6373f",
   "metadata": {},
   "source": [
    "### Sample use of the clean_salary function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "182eac4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Salary\n",
      "0    50000.0\n",
      "1    20800.0\n",
      "2   104000.0\n",
      "3    60000.0\n",
      "4    75000.0\n",
      "5   100000.0\n",
      "6   150000.0\n",
      "7   416000.0\n",
      "8     3000.0\n",
      "9        NaN\n",
      "10       NaN\n",
      "11       NaN\n",
      "12  145600.0\n"
     ]
    }
   ],
   "source": [
    "test_df = pd.DataFrame({\n",
    "    \"Salary\": [\"$50k\", \"10\", \"50\", \"60,000\", \"70,000-80,000\", \"100k\", \"150000\", \"200\", \"3000\", \"5000000\", \"$1.5M\", \"invalid\", 70]\n",
    "})\n",
    "\n",
    "# Create instance with test DataFrame\n",
    "cleaner = DataCleaner(test_df)\n",
    "\n",
    "# Run salary cleaning\n",
    "cleaner = cleaner.clean_salary(2080)\n",
    "\n",
    "# Get the cleaned DataFrame\n",
    "result_df = cleaner.finalize()\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6d393f",
   "metadata": {},
   "source": [
    "# Example of making a test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "82806fc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Salary\n",
      "0      NaN\n",
      "1      NaN\n",
      "2      NaN\n",
      "3      NaN\n",
      "4  50000.0\n",
      "5   5000.0\n",
      "6      NaN\n",
      "7      NaN\n",
      "8      NaN\n",
      "9  75000.0\n"
     ]
    }
   ],
   "source": [
    "fail_df = pd.DataFrame({\n",
    "    \"Salary\": [\n",
    "        None,                # NaN input\n",
    "        \"\",                  # empty string\n",
    "        \" \",                 # whitespace only\n",
    "        \"abc123\",            # text + numbers\n",
    "        \"50k-abc\",           # malformed range\n",
    "        \"$-5000\",            # negative salary\n",
    "        \"∞\",                 # infinity symbol\n",
    "        \"NaN\",               # literal string NaN\n",
    "        \"$1.5M\",             # millions, not handled in parser\n",
    "        \"70,000—80,000\"      # em dash (—) instead of hyphen/dash\n",
    "    ]\n",
    "})\n",
    "# Create instance with failing DataFrame\n",
    "fail_cleaner = DataCleaner(fail_df)\n",
    "# Run salary cleaning on failing DataFrame\n",
    "fail_cleaner = fail_cleaner.clean_salary(2080)\n",
    "# Get the cleaned DataFrame\n",
    "fail_result_df = fail_cleaner.finalize()\n",
    "print(fail_result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "123deb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataCleaner:\n",
    "    def __init__(self, df: pd.DataFrame):\n",
    "        self.df = df.copy()\n",
    "\n",
    "    def clean_salary(self, hours_per_year: int = 2080):\n",
    "        \"\"\"\n",
    "        Clean and standardize salary values in the DataFrame.\n",
    "\n",
    "        Steps performed:\n",
    "        1. Remove currency symbols, commas, and shorthand (e.g., \"$50k\" → 50000).\n",
    "        2. Handle ranges by converting them to the average value \n",
    "           (e.g., \"50,000–70,000\" → 60000).\n",
    "        3. Handle shorthand \"M\" (e.g., \"$1.5M\" → 1,500,000).\n",
    "        4. Convert values to numeric, coercing invalid entries to NaN.\n",
    "        5. Treat values <= 200 as hourly wages and convert to annual salaries \n",
    "           (multiplied by `hours_per_year`).\n",
    "        6. Drop unrealistic values greater than 1,000,000 (set to NaN).\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        hours_per_year : int, optional (default=2080)\n",
    "            Number of work hours in a year for converting hourly to annual salary.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "            The current instance with the cleaned Salary column.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if \"Salary\" in self.df.columns:\n",
    "                self.df[\"Salary\"] = self.df[\"Salary\"].astype(str)\n",
    "\n",
    "                def parse_salary(val: str):\n",
    "                    val = val.strip()\n",
    "                    if not val or val.lower() in {\"nan\", \"none\"}:\n",
    "                        return None\n",
    "\n",
    "                    # Normalize dash types (hyphen, en dash, em dash \"-\")\n",
    "                    val = re.sub(r\"[–—]\", \"-\", val)\n",
    "\n",
    "                    # Handle range like \"50k-70k\" or \"50,000-70,000\"\n",
    "                    if \"-\" in val:\n",
    "                        parts = val.split(\"-\")\n",
    "                        nums = [parse_salary(p) for p in parts if p.strip()]\n",
    "                        nums = [n for n in nums if n is not None]\n",
    "                        return sum(nums) / len(nums) if nums else None\n",
    "\n",
    "                    # Remove $, commas, spaces\n",
    "                    val = re.sub(r\"[\\$,]\", \"\", val)\n",
    "\n",
    "                    # Handle shorthand k/K (e.g., \"50k\" → 50000)\n",
    "                    match_k = re.match(r\"^(\\d+(\\.\\d+)?)[kK]$\", val)\n",
    "                    if match_k:\n",
    "                        return float(match_k.group(1)) * 1000\n",
    "\n",
    "                    # Handle shorthand M (e.g., \"1.5M\" → 1500000)\n",
    "                    match_m = re.match(r\"^(\\d+(\\.\\d+)?)[mM]$\", val)\n",
    "                    if match_m:\n",
    "                        return float(match_m.group(1)) * 1_000_000\n",
    "\n",
    "                    # Plain number (integer or float)\n",
    "                    try:\n",
    "                        return float(val)\n",
    "                    except ValueError:\n",
    "                        return None\n",
    "\n",
    "                # Apply parsing\n",
    "                self.df[\"Salary\"] = self.df[\"Salary\"].apply(parse_salary)\n",
    "\n",
    "                # Convert small numbers (hourly) to annual\n",
    "                self.df.loc[self.df[\"Salary\"] <=\n",
    "                            200, \"Salary\"] *= hours_per_year\n",
    "\n",
    "                # Drop unrealistic salaries\n",
    "                self.df.loc[self.df[\"Salary\"] > 1_000_000, \"Salary\"] = None\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[Warning] Failed salary cleaning: {e}\")\n",
    "\n",
    "        return self\n",
    "\n",
    "    def finalize(self):\n",
    "        \"\"\"Return cleaned dataframe.\"\"\"\n",
    "        return self.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "688bdf74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Salary cleaning DataFrame test passed!\n"
     ]
    }
   ],
   "source": [
    "# Test DataFrame with edge/fail cases\n",
    "fail_df = pd.DataFrame({\n",
    "    \"Salary\": [\n",
    "        None,  # NaN\n",
    "        \"\",  # NaN\n",
    "        \" \",  # NaN\n",
    "        \"abc123\",  # NaN\n",
    "        \"50k-abc\",  # 50000.0\n",
    "        \"$-5000\",  # -5000.0  (still allowed for now)\n",
    "        \"∞\",  # NaN\n",
    "        \"NaN\",  # NaN\n",
    "        \"$1.5M\",  # NaN ( >1,000,000 rule)\n",
    "        \"70,000—80,000\"  # 75000.0 (dash normalized)\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Run through cleaner\n",
    "cleaner = DataCleaner(fail_df)\n",
    "result = cleaner.clean_salary().finalize().reset_index(drop=True)\n",
    "\n",
    "# Expected results as DataFrame\n",
    "expected = pd.DataFrame({\n",
    "    \"Salary\": [\n",
    "        None,       # None\n",
    "        None,       # empty string\n",
    "        None,       # whitespace\n",
    "        None,       # abc123\n",
    "        50000.0,    # 50k-abc\n",
    "        5000.0,     # negative salary\n",
    "        None,       # infinity\n",
    "        None,       # \"NaN\"\n",
    "        None,       # 1.5M filtered out\n",
    "        75000.0     # range with em dash\n",
    "    ]\n",
    "}, dtype=\"float64\").reset_index(drop=True)\n",
    "\n",
    "# Assertion test\n",
    "pdt.assert_frame_equal(result, expected)\n",
    "print(\"✅ Salary cleaning DataFrame test passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ddbb4c0",
   "metadata": {},
   "source": [
    "## Generate report\n",
    "\n",
    "- Overall completion of program only accounting for the new style of classes m1-m4\n",
    "- completion by year\n",
    "- completion over all by pathway\n",
    "- completion by year by pathway\n",
    "- Feel free to get creative here adding gender etc to get us a better understanding\n",
    "- education level and the above...\n",
    "- export this as a txt file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e5b989d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['ARC_Enrollments', 'ARC_Application', 'All_demographics_and_programs'])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4a72a66d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KY Region</th>\n",
       "      <th>Contact: Auto Id</th>\n",
       "      <th>Contact: Unique ID SSN</th>\n",
       "      <th>Contact: SSN Opt Out</th>\n",
       "      <th>Contact: Mailing State/Province</th>\n",
       "      <th>Contact: County</th>\n",
       "      <th>Contact: Mailing Zip/Postal Code</th>\n",
       "      <th>Contact: Birthdate</th>\n",
       "      <th>Contact: Gender</th>\n",
       "      <th>Disability</th>\n",
       "      <th>...</th>\n",
       "      <th>Displaced Homemaker</th>\n",
       "      <th>Spouse of Armed Forces Reduced Income</th>\n",
       "      <th>Loss of Family Support</th>\n",
       "      <th>Seasonal farm worker?</th>\n",
       "      <th>Contact: First Name</th>\n",
       "      <th>Contact: Last Name</th>\n",
       "      <th>Status</th>\n",
       "      <th>Date Completed</th>\n",
       "      <th>Assessment: Created Date</th>\n",
       "      <th>Contact: Approval Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SOAR</td>\n",
       "      <td>202109-5224</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>KY</td>\n",
       "      <td>Knox</td>\n",
       "      <td>40906</td>\n",
       "      <td>1981-10-25</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>name</td>\n",
       "      <td>name</td>\n",
       "      <td>Accepted - Prework Complete</td>\n",
       "      <td>2021-08-24</td>\n",
       "      <td>2021-09-10</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SOAR</td>\n",
       "      <td>202109-5230</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>KY</td>\n",
       "      <td>Perry</td>\n",
       "      <td>41773</td>\n",
       "      <td>2000-10-28</td>\n",
       "      <td>Prefer not to say</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>name</td>\n",
       "      <td>name</td>\n",
       "      <td>Accepted - Prework Complete</td>\n",
       "      <td>2021-08-25</td>\n",
       "      <td>2021-09-10</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  KY Region Contact: Auto Id  Contact: Unique ID SSN  Contact: SSN Opt Out  \\\n",
       "0      SOAR      202109-5224                     NaN                     0   \n",
       "1      SOAR      202109-5230                     NaN                     0   \n",
       "\n",
       "  Contact: Mailing State/Province Contact: County  \\\n",
       "0                              KY            Knox   \n",
       "1                              KY           Perry   \n",
       "\n",
       "   Contact: Mailing Zip/Postal Code Contact: Birthdate    Contact: Gender  \\\n",
       "0                             40906         1981-10-25             Female   \n",
       "1                             41773         2000-10-28  Prefer not to say   \n",
       "\n",
       "  Disability  ... Displaced Homemaker Spouse of Armed Forces Reduced Income  \\\n",
       "0         No  ...                 NaN                                   NaN   \n",
       "1         No  ...                 NaN                                   NaN   \n",
       "\n",
       "  Loss of Family Support Seasonal farm worker?  Contact: First Name  \\\n",
       "0                    NaN                   NaN                 name   \n",
       "1                    NaN                   NaN                 name   \n",
       "\n",
       "  Contact: Last Name                       Status Date Completed  \\\n",
       "0               name  Accepted - Prework Complete     2021-08-24   \n",
       "1               name  Accepted - Prework Complete     2021-08-25   \n",
       "\n",
       "   Assessment: Created Date Contact: Approval Status  \n",
       "0                2021-09-10                      NaN  \n",
       "1                2021-09-10                      NaN  \n",
       "\n",
       "[2 rows x 40 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arc_apps = dfs['ARC_Application']\n",
    "arc_apps.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f952beff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Auto Id</th>\n",
       "      <th>KY Region</th>\n",
       "      <th>Full Name</th>\n",
       "      <th>Assessment ID</th>\n",
       "      <th>EnrollmentId</th>\n",
       "      <th>Enrollment Service Name</th>\n",
       "      <th>Service</th>\n",
       "      <th>Projected Start Date</th>\n",
       "      <th>Actual Start Date</th>\n",
       "      <th>Projected End Date</th>\n",
       "      <th>Actual End Date</th>\n",
       "      <th>Outcome</th>\n",
       "      <th>ATP Cohort</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>202109-5224</td>\n",
       "      <td>SOAR</td>\n",
       "      <td>name name</td>\n",
       "      <td>OA-003348</td>\n",
       "      <td>Enrollment-1386</td>\n",
       "      <td>ES-0011193</td>\n",
       "      <td>Career Readiness Workshop</td>\n",
       "      <td>2021-11-11</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>202109-5224</td>\n",
       "      <td>SOAR</td>\n",
       "      <td>name name</td>\n",
       "      <td>OA-003348</td>\n",
       "      <td>Enrollment-1386</td>\n",
       "      <td>ES-0013492</td>\n",
       "      <td>Software Development 1</td>\n",
       "      <td>2022-01-05</td>\n",
       "      <td>2022-01-05</td>\n",
       "      <td>2022-04-06</td>\n",
       "      <td>2022-04-06</td>\n",
       "      <td>Successfully Completed</td>\n",
       "      <td>2022-01-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Auto Id KY Region   Full Name Assessment ID     EnrollmentId  \\\n",
       "0  202109-5224      SOAR  name name      OA-003348  Enrollment-1386   \n",
       "1  202109-5224      SOAR  name name      OA-003348  Enrollment-1386   \n",
       "\n",
       "  Enrollment Service Name                    Service Projected Start Date  \\\n",
       "0              ES-0011193  Career Readiness Workshop           2021-11-11   \n",
       "1              ES-0013492     Software Development 1           2022-01-05   \n",
       "\n",
       "  Actual Start Date Projected End Date Actual End Date  \\\n",
       "0               NaT                NaT             NaT   \n",
       "1        2022-01-05         2022-04-06      2022-04-06   \n",
       "\n",
       "                  Outcome ATP Cohort  \n",
       "0                     NaN        NaT  \n",
       "1  Successfully Completed 2022-01-01  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arc_enroll = dfs['ARC_Enrollments']\n",
    "arc_enroll.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b1d04a",
   "metadata": {},
   "source": [
    "# pathway information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8d6485e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "STARTER_PATHWAYS = [\n",
    "    'Web Development M1',\n",
    "    'Data Analysis M1',\n",
    "    'Software Development M1',\n",
    "    'Quality Assurance M1',\n",
    "    'User Experience M1',\n",
    "]\n",
    "\n",
    "def get_starting_pathways(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Returns a DataFrame containing only the starting pathways.\n",
    "    \"\"\"\n",
    "    mask_starter_pathways = df['Service'].isin(STARTER_PATHWAYS)\n",
    "    return df[mask_starter_pathways]\n",
    "\n",
    "\n",
    "def get_cohorts_list(df: pd.DataFrame) -> list:\n",
    "    \"\"\"\n",
    "    Returns a sorted list of cohorts from starting pathways, including 'All cohorts'.\n",
    "    \"\"\"\n",
    "    df_starters = get_starting_pathways(df)\n",
    "    cohorts = list(\n",
    "        pd.to_datetime(df_starters['ATP Cohort'][df_starters['ATP Cohort'] != 'NA'])\n",
    "        .sort_values()\n",
    "        .astype(str)\n",
    "        .unique()\n",
    "    )\n",
    "    cohorts.insert(0, 'All cohorts')\n",
    "    return cohorts\n",
    "\n",
    "\n",
    "def get_data_by_cohort(df: pd.DataFrame, cohort: str = 'All cohorts') -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Returns a DataFrame counting services for a specific cohort or all cohorts.\n",
    "    \"\"\"\n",
    "    df_starters = get_starting_pathways(df)\n",
    "    if cohort == 'All cohorts':\n",
    "        result = df_starters.value_counts('Service').reset_index()\n",
    "    else:\n",
    "        cohort_dt = str(pd.to_datetime(cohort))\n",
    "        result = df_starters[df_starters['ATP Cohort'] == cohort_dt].value_counts('Service').reset_index()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a4dda144",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['All cohorts',\n",
       " '2023-05-01',\n",
       " '2023-08-01',\n",
       " '2024-01-01',\n",
       " '2024-05-01',\n",
       " '2024-08-01',\n",
       " '2025-01-01']"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cohorts = get_cohorts_list(arc_enroll)\n",
    "cohorts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "2985783d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Service</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Analysis M1</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Web Development M1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Software Development M1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Service  count\n",
       "0         Data Analysis M1     17\n",
       "1       Web Development M1     14\n",
       "2  Software Development M1     11"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enroll_by_cohort = get_data_by_cohort(arc_enroll, \"2024-01-01\")\n",
    "enroll_by_cohort"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd94d97",
   "metadata": {},
   "source": [
    "Completion information "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "4a0e9551",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Completion_rate_data:\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.__pathways = [\n",
    "            'Web Development M1',\n",
    "            'Web Development M2',\n",
    "            'Web Development M3',\n",
    "            'Web Development M4',\n",
    "            'Data Analysis M1',\n",
    "            'Data Analysis M2',\n",
    "            'Data Analysis M3',\n",
    "            'Data Analysis M4',\n",
    "            'Software Development M1',\n",
    "            'Software Development M2',\n",
    "            'Software Development M3',\n",
    "            'Software Development M4',\n",
    "            'Quality Assurance M1',\n",
    "            'Quality Assurance M2',\n",
    "            'Quality Assurance M3',\n",
    "            'Quality Assurance M4',\n",
    "            'User Experience M1',\n",
    "            'User Experience M2',\n",
    "            'User Experience M3',\n",
    "            'User Experience M4',\n",
    "        ]\n",
    "\n",
    "        # Not the best Pandas way to do it:\n",
    "    def Get_completion_percentages(self,\n",
    "                                   cohort: str = 'All cohorts') -> pd.DataFrame:  # noqa\n",
    "        \"\"\"\n",
    "            Creates a pandas.Datafreme that contains the %\n",
    "            of completion of each pathway.\n",
    "\n",
    "            Args:\n",
    "                cohort: str\n",
    "\n",
    "            Return:\n",
    "                pandas.DataFrame\n",
    "        \"\"\"\n",
    "        if cohort == 'All cohorts':\n",
    "            data = self.data\n",
    "        else:\n",
    "            data = self.data[self.data['ATP Cohort'] == pd.Timestamp(cohort)]\n",
    "\n",
    "        completion_dictionary = {}\n",
    "\n",
    "        for path in self.__pathways:\n",
    "            outcome = data[data['Service'] == path]['Outcome'].value_counts(\n",
    "                normalize=True).reset_index()\n",
    "            completion_dictionary[path] = {\n",
    "                row.Outcome: row.proportion for row in outcome.itertuples(index=True)}  # noqa\n",
    "\n",
    "        result_df = pd.DataFrame(completion_dictionary).transpose().fillna(\n",
    "            0).rename_axis('Module').reset_index()\n",
    "\n",
    "        result_df['Pathway'] = result_df['Module'].apply(\n",
    "            # intended to be able to sort by pathway\n",
    "            lambda x: x[:x.rfind(' ')])\n",
    "        return result_df\n",
    "\n",
    "    def Get_pathways_name(self, df: pd.DataFrame) -> list:\n",
    "        \"\"\"\n",
    "            List of all the pathways in a pandas.DataFrame generated by\n",
    "            self.Get_completion_percentages().\n",
    "\n",
    "            Args:\n",
    "                df: pandas.DataFrame\n",
    "\n",
    "            Return:\n",
    "                list\n",
    "        \"\"\"\n",
    "        return list(df['Pathway'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "7e3c6bfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Module</th>\n",
       "      <th>Successfully Completed</th>\n",
       "      <th>Did Not Complete</th>\n",
       "      <th>Pathway</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Web Development M1</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>Web Development</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Web Development M2</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>Web Development</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Web Development M3</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>Web Development</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Web Development M4</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>Web Development</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Analysis M1</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>Data Analysis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Analysis M2</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>Data Analysis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Analysis M3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Data Analysis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Analysis M4</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>Data Analysis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Software Development M1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Software Development</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Software Development M2</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>Software Development</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Software Development M3</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>Software Development</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Software Development M4</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>Software Development</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Quality Assurance M1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Quality Assurance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Quality Assurance M2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Quality Assurance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Quality Assurance M3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Quality Assurance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Quality Assurance M4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Quality Assurance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>User Experience M1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>User Experience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>User Experience M2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>User Experience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>User Experience M3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>User Experience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>User Experience M4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>User Experience</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Module  Successfully Completed  Did Not Complete  \\\n",
       "0        Web Development M1                0.750000          0.250000   \n",
       "1        Web Development M2                0.714286          0.285714   \n",
       "2        Web Development M3                0.800000          0.200000   \n",
       "3        Web Development M4                0.750000          0.250000   \n",
       "4          Data Analysis M1                0.714286          0.285714   \n",
       "5          Data Analysis M2                0.500000          0.500000   \n",
       "6          Data Analysis M3                1.000000          0.000000   \n",
       "7          Data Analysis M4                0.333333          0.666667   \n",
       "8   Software Development M1                1.000000          0.000000   \n",
       "9   Software Development M2                0.818182          0.181818   \n",
       "10  Software Development M3                0.777778          0.222222   \n",
       "11  Software Development M4                0.714286          0.285714   \n",
       "12     Quality Assurance M1                0.000000          0.000000   \n",
       "13     Quality Assurance M2                0.000000          0.000000   \n",
       "14     Quality Assurance M3                0.000000          0.000000   \n",
       "15     Quality Assurance M4                0.000000          0.000000   \n",
       "16       User Experience M1                0.000000          0.000000   \n",
       "17       User Experience M2                0.000000          0.000000   \n",
       "18       User Experience M3                0.000000          0.000000   \n",
       "19       User Experience M4                0.000000          0.000000   \n",
       "\n",
       "                 Pathway  \n",
       "0        Web Development  \n",
       "1        Web Development  \n",
       "2        Web Development  \n",
       "3        Web Development  \n",
       "4          Data Analysis  \n",
       "5          Data Analysis  \n",
       "6          Data Analysis  \n",
       "7          Data Analysis  \n",
       "8   Software Development  \n",
       "9   Software Development  \n",
       "10  Software Development  \n",
       "11  Software Development  \n",
       "12     Quality Assurance  \n",
       "13     Quality Assurance  \n",
       "14     Quality Assurance  \n",
       "15     Quality Assurance  \n",
       "16       User Experience  \n",
       "17       User Experience  \n",
       "18       User Experience  \n",
       "19       User Experience  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion_data = Completion_rate_data(arc_enroll)\n",
    "completion = completion_data.Get_completion_percentages('2023-05-01')\n",
    "completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "142e9f0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Module</th>\n",
       "      <th>Successfully Completed</th>\n",
       "      <th>Did Not Complete</th>\n",
       "      <th>Partially Completed</th>\n",
       "      <th>Pathway</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Web Development M1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Web Development</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Web Development M2</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Web Development</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Web Development M3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Web Development</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Web Development M4</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Web Development</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Analysis M1</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>Data Analysis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Analysis M2</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Data Analysis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Analysis M3</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Data Analysis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Analysis M4</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Data Analysis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Software Development M1</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Software Development</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Software Development M2</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>Software Development</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Software Development M3</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Software Development</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Software Development M4</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Software Development</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Quality Assurance M1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Quality Assurance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Quality Assurance M2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Quality Assurance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Quality Assurance M3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Quality Assurance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Quality Assurance M4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Quality Assurance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>User Experience M1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>User Experience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>User Experience M2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>User Experience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>User Experience M3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>User Experience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>User Experience M4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>User Experience</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Module  Successfully Completed  Did Not Complete  \\\n",
       "0        Web Development M1                1.000000          0.000000   \n",
       "1        Web Development M2                0.857143          0.142857   \n",
       "2        Web Development M3                1.000000          0.000000   \n",
       "3        Web Development M4                0.666667          0.333333   \n",
       "4          Data Analysis M1                0.764706          0.117647   \n",
       "5          Data Analysis M2                0.846154          0.153846   \n",
       "6          Data Analysis M3                0.909091          0.090909   \n",
       "7          Data Analysis M4                0.500000          0.500000   \n",
       "8   Software Development M1                0.818182          0.181818   \n",
       "9   Software Development M2                0.555556          0.222222   \n",
       "10  Software Development M3                0.800000          0.200000   \n",
       "11  Software Development M4                0.250000          0.750000   \n",
       "12     Quality Assurance M1                0.000000          0.000000   \n",
       "13     Quality Assurance M2                0.000000          0.000000   \n",
       "14     Quality Assurance M3                0.000000          0.000000   \n",
       "15     Quality Assurance M4                0.000000          0.000000   \n",
       "16       User Experience M1                0.000000          0.000000   \n",
       "17       User Experience M2                0.000000          0.000000   \n",
       "18       User Experience M3                0.000000          0.000000   \n",
       "19       User Experience M4                0.000000          0.000000   \n",
       "\n",
       "    Partially Completed               Pathway  \n",
       "0              0.000000       Web Development  \n",
       "1              0.000000       Web Development  \n",
       "2              0.000000       Web Development  \n",
       "3              0.000000       Web Development  \n",
       "4              0.117647         Data Analysis  \n",
       "5              0.000000         Data Analysis  \n",
       "6              0.000000         Data Analysis  \n",
       "7              0.000000         Data Analysis  \n",
       "8              0.000000  Software Development  \n",
       "9              0.222222  Software Development  \n",
       "10             0.000000  Software Development  \n",
       "11             0.000000  Software Development  \n",
       "12             0.000000     Quality Assurance  \n",
       "13             0.000000     Quality Assurance  \n",
       "14             0.000000     Quality Assurance  \n",
       "15             0.000000     Quality Assurance  \n",
       "16             0.000000       User Experience  \n",
       "17             0.000000       User Experience  \n",
       "18             0.000000       User Experience  \n",
       "19             0.000000       User Experience  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_completion_data = Completion_rate_data(arc_enroll)\n",
    "all_completion = completion_data.Get_completion_percentages(\"All cohorts\")\n",
    "completion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859cf674",
   "metadata": {},
   "source": [
    "## Plots\n",
    "\n",
    "- Look at the various plots\n",
    "- make a consistent color scheme\n",
    "- pick the plots that go with the report above\n",
    "- make missing plots\n",
    "- make plots have the option to show & save in the functions\n",
    "\n",
    "see `src/notebooks/visualization_examples.ipynb`\n",
    "See below from `src/Carmen_WORCEmployment_Plots.py`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81009a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_salary_by_gender(data):\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    sns.boxplot(data=data, x='Gender', y='Salary')\n",
    "    plt.title(\"Salary Distribution by Gender\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_avg_salary_by_city(data):\n",
    "    region_salary = data.groupby('Mailing City')['Salary'].mean().sort_values()\n",
    "    region_salary.plot(kind='barh', figsize=(\n",
    "        8, 5), title=\"Average Salary by KY Region\")\n",
    "    plt.xlabel(\"Average Salary\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_placements_over_time(data):\n",
    "    data.set_index('Start Date').resample('M').size().plot(\n",
    "        kind='line', marker='o', figsize=(10, 4))\n",
    "    plt.title(\"Number of Placements Over Time\")\n",
    "    plt.ylabel(\"Placements\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_placement_type_by_program(data):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.countplot(data=data, x='ATP Placement Type',\n",
    "                  hue='Program: Program Name')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.title(\"Placement Type by Program\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_top_cities(data):\n",
    "    city_counts = data['Mailing City'].value_counts().head(10)\n",
    "    city_counts.plot(\n",
    "        kind='bar', title='Top Cities by Participant Count', figsize=(8, 4))\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f905708f",
   "metadata": {},
   "source": [
    "# TOC generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d4fc7116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- ✅ Copy the Markdown below and paste it into a new markdown cell ---\n",
      "\n",
      "### **Table of Contents**\n",
      "  * [**Table of Contents**](#**table-of-contents**)\n",
      "  * [Function To Read in the Data!](#function-to-read-in-the-data!)\n",
      "  * [Example usage](#example-usage)\n",
      "      * [To Access a DataFrame in the list](#to-access-a-dataframe-in-the-list)\n",
      "      * [To Remove Spaces in DataFrame name](#to-remove-spaces-in-dataframe-name)\n",
      "  * [Update cleaning code](#update-cleaning-code)\n",
      "* [example usage of each method](#example-usage-of-each-method)\n",
      "    * [Sample use of the clean_salary function.](#sample-use-of-the-clean_salary-function)\n",
      "* [Example of making a test](#example-of-making-a-test)\n",
      "  * [Generate report](#generate-report)\n",
      "* [pathway information](#pathway-information)\n",
      "  * [Plots](#plots)\n",
      "* [TOC generator](#toc-generator)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "\n",
    "def generate_toc_from_notebook(notebook_path):\n",
    "    \"\"\"\n",
    "    Parses a local .ipynb file and generates Markdown for a Table of Contents.\n",
    "    \"\"\"\n",
    "    if not os.path.isfile(notebook_path):\n",
    "        print(f\"❌ Error: File not found at '{notebook_path}'\")\n",
    "        return\n",
    "\n",
    "    with open(notebook_path, 'r', encoding='utf-8') as f:\n",
    "        notebook = json.load(f)\n",
    "\n",
    "    toc_markdown = \"### **Table of Contents**\\n\"\n",
    "    for cell in notebook.get('cells', []):\n",
    "        if cell.get('cell_type') == 'markdown':\n",
    "            for line in cell.get('source', []):\n",
    "                if line.strip().startswith('#'):\n",
    "                    level = line.count('#')\n",
    "                    title = line.strip('#').strip()\n",
    "                    link = title.lower().replace(' ', '-').strip('-.()')\n",
    "                    indent = '  ' * (level - 1)\n",
    "                    toc_markdown += f\"{indent}* [{title}](#{link})\\n\"\n",
    "\n",
    "    print(\"\\n--- ✅ Copy the Markdown below and paste it \"\n",
    "          \"into a new markdown cell ---\\n\")\n",
    "    print(toc_markdown)\n",
    "\n",
    "\n",
    "notebook_path = 'mainNb.ipynb'\n",
    "generate_toc_from_notebook(notebook_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
